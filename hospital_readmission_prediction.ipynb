{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c61de6c8",
   "metadata": {},
   "source": [
    "# ðŸ¥ Predicting Hospital Readmission Rates\n",
    "An end-to-end machine learning + deep learning pipeline using synthetic hospital data.\n",
    "Models used: Logistic Regression, Random Forest, XGBoost, MLP (TensorFlow).\n",
    "Includes: Data generation, preprocessing, training, evaluation, ROC comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007728e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866da584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "data = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 90, n_samples),\n",
    "    'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "    'length_of_stay': np.random.randint(1, 30, n_samples),\n",
    "    'num_prev_admissions': np.random.randint(0, 10, n_samples),\n",
    "    'comorbidity_score': np.random.normal(loc=2, scale=1, size=n_samples).round(1),\n",
    "    'has_diabetes': np.random.choice([0, 1], n_samples),\n",
    "    'has_hypertension': np.random.choice([0, 1], n_samples),\n",
    "    'discharged_to_home': np.random.choice([0, 1], n_samples),\n",
    "    'readmitted_within_30_days': np.random.choice([0, 1], n_samples, p=[0.7, 0.3])\n",
    "})\n",
    "data['gender'] = LabelEncoder().fit_transform(data['gender'])\n",
    "\n",
    "# Split data\n",
    "X = data.drop('readmitted_within_30_days', axis=1)\n",
    "y = data['readmitted_within_30_days']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a561c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classical ML models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "roc_data = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_data[name] = (fpr, tpr, auc(fpr, tpr))\n",
    "    print(f\"\\n{name} Accuracy: {accuracy_score(y_test, model.predict(X_test)):.2f}\")\n",
    "    print(classification_report(y_test, model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001bf42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP with TensorFlow\n",
    "mlp_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = mlp_model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[early_stop], verbose=0)\n",
    "\n",
    "# Evaluate and store ROC\n",
    "y_proba_dl = mlp_model.predict(X_test).ravel()\n",
    "fpr_dl, tpr_dl, _ = roc_curve(y_test, y_proba_dl)\n",
    "roc_data[\"MLP (Deep Learning)\"] = (fpr_dl, tpr_dl, auc(fpr_dl, tpr_dl))\n",
    "\n",
    "print(f\"\\nMLP Accuracy: {mlp_model.evaluate(X_test, y_test, verbose=0)[1]:.2f}\")\n",
    "y_pred_dl = (y_proba_dl > 0.5).astype('int')\n",
    "print(classification_report(y_test, y_pred_dl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdaaefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve Comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, (fpr, tpr, roc_auc) in roc_data.items():\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bcf232",
   "metadata": {},
   "source": [
    "### ðŸ“Š Summary\n",
    "- XGBoost and MLP performed best in terms of ROC AUC.\n",
    "- MLP captured nonlinear relationships but took longer to train.\n",
    "- Logistic Regression gave fast, interpretable results.\n",
    "- Future work: use real patient data (e.g. MIMIC-III), hyperparameter tuning, feature engineering."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
